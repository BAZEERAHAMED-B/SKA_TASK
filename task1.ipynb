{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNTq0iPy3Gk7r4OOa4pB9rR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"u2MSWfXn9gAU"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","!pip install medmnist\n","from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import numpy as np"]},{"cell_type":"code","source":["!pip install nbformat"],"metadata":{"id":"9J_YoPIriDAR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import nbformat\n","nb = nbformat.read(\"task1.ipynb\", as_version=4)\n","nbformat.write(nb, \"task1_clean.ipynb\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":408},"id":"jYHAI1vZiLAY","executionInfo":{"status":"error","timestamp":1771414730195,"user_tz":-240,"elapsed":7,"user":{"displayName":"BAZEER AHAMED B","userId":"01361351138262175864"}},"outputId":"9835e5a8-1eb1-4ae9-b01a-96e57909baf0"},"execution_count":3,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'task1.ipynb'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/nbformat/__init__.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(fp, as_version, capture_validation_error, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'read'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-842196321.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnbformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnbformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"task1.ipynb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnbformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"task1_clean.ipynb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/nbformat/__init__.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(fp, as_version, capture_validation_error, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: PTH123\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mreads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapture_validation_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'task1.ipynb'"]}]},{"cell_type":"code","source":["import os\n","print(os.getcwd())\n","print(os.listdir())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R0dQe65TjEyn","executionInfo":{"status":"ok","timestamp":1771414772291,"user_tz":-240,"elapsed":7,"user":{"displayName":"BAZEER AHAMED B","userId":"01361351138262175864"}},"outputId":"79af5be8-e3a2-49f3-da0b-ecbbe749a142"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","['.config', 'sample_data']\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"09wOVs3gjJAd","executionInfo":{"status":"ok","timestamp":1771414806598,"user_tz":-240,"elapsed":18255,"user":{"displayName":"BAZEER AHAMED B","userId":"01361351138262175864"}},"outputId":"9f81b227-2913-4e6f-9cd6-264f692574cb"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["file_path = \"/content/drive/MyDrive/path_to_your_file/task1.ipynb\"\n"],"metadata":{"id":"QtbXO-d2jRKl","executionInfo":{"status":"ok","timestamp":1771414821826,"user_tz":-240,"elapsed":6,"user":{"displayName":"BAZEER AHAMED B","userId":"01361351138262175864"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["from google.colab import files\n","uploaded = files.upload()\n"],"metadata":{"id":"xlVgCsDSjVbW","outputId":"7655d23f-4e8b-459b-9338-fe172c16230f","colab":{"base_uri":"https://localhost:8080/","height":38}},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-2a5abd95-0457-48bf-8cc1-b3ab7c649d4d\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-2a5abd95-0457-48bf-8cc1-b3ab7c649d4d\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}}]},{"cell_type":"code","source":["train_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.RandomRotation(10),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.Normalize(mean=[0.5], std=[0.5])\n","])\n","\n","test_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.5], std=[0.5])\n","])\n"],"metadata":{"id":"2ItnqILu-cCz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from medmnist import PneumoniaMNIST\n","!pip install medmnist\n","\n","train_dataset = PneumoniaMNIST(split='train', transform=train_transform, download=True)\n","val_dataset = PneumoniaMNIST(split='val', transform=test_transform, download=True)\n","test_dataset = PneumoniaMNIST(split='test', transform=test_transform, download=True)\n","\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"],"metadata":{"id":"M1C8rvz8-lSL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from medmnist import PneumoniaMNIST"],"metadata":{"id":"uWoCG5u1-4LT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","from medmnist import PneumoniaMNIST\n"],"metadata":{"id":"n5HfNex4-7nz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset = PneumoniaMNIST(split='train', transform=train_transform, download=True)\n","val_dataset = PneumoniaMNIST(split='val', transform=test_transform, download=True)\n","test_dataset = PneumoniaMNIST(split='test', transform=test_transform, download=True)\n","\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"],"metadata":{"id":"IiSf4O7Y---D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class SimpleCNN(nn.Module):\n","    def __init__(self):\n","        super(SimpleCNN, self).__init__()\n","        self.features = nn.Sequential(\n","            nn.Conv2d(1, 32, 3, padding=1),\n","            nn.BatchNorm2d(32),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),\n","\n","            nn.Conv2d(32, 64, 3, padding=1),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),\n","\n","            nn.Conv2d(64, 128, 3, padding=1),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(),\n","            nn.AdaptiveAvgPool2d(1)\n","        )\n","\n","        self.classifier = nn.Linear(128, 1)\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = torch.flatten(x, 1)\n","        x = self.classifier(x)\n","        return x\n"],"metadata":{"id":"M5v79L1c_Cf7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = SimpleCNN()\n","criterion = nn.BCEWithLogitsLoss()\n","optimizer = optim.Adam(model.parameters(), lr=1e-3)\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n"],"metadata":{"id":"XpB5_f2z_HVb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def evaluate(model, loader):\n","    model.eval()\n","    preds, probs, labels_list = [], [], []\n","\n","    with torch.no_grad():\n","        for images, labels in loader:\n","            outputs = model(images).squeeze()\n","            probability = torch.sigmoid(outputs)\n","\n","            preds.extend((probability > 0.5).int().numpy())\n","            probs.extend(probability.numpy())\n","            labels_list.extend(labels.numpy())\n","\n","    return np.array(preds), np.array(probs), np.array(labels_list)\n"],"metadata":{"id":"YLa0jrQ-_KlS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["preds, probs, labels = evaluate(model, test_loader)\n","\n","print(classification_report(labels, preds))\n"],"metadata":{"id":"fp-eQzkh_PLT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cm = confusion_matrix(labels, preds)\n","\n","sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n","plt.xlabel(\"Predicted\")\n","plt.ylabel(\"Actual\")\n","plt.title(\"Confusion Matrix\")\n","plt.show()\n"],"metadata":{"id":"0gLqFA7w_SNj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["auc = roc_auc_score(labels, probs)\n","fpr, tpr, _ = roc_curve(labels, probs)\n","\n","plt.plot(fpr, tpr, label=f\"AUC = {auc:.3f}\")\n","plt.plot([0,1],[0,1],'--')\n","plt.xlabel(\"False Positive Rate\")\n","plt.ylabel(\"True Positive Rate\")\n","plt.title(\"ROC Curve\")\n","plt.legend()\n","plt.show()\n"],"metadata":{"id":"MqwCOT8g_YIr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["misclassified_indices = np.where(preds != labels)[0]\n"],"metadata":{"id":"241V6M6O_bWC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for idx in misclassified_indices[:5]:\n","    image, label = test_dataset[idx]\n","    plt.imshow(image.squeeze(), cmap='gray')\n","    plt.title(f\"True: {label}, Predicted: {preds[idx]}\")\n","    plt.show()\n"],"metadata":{"id":"a81TSOyp_eeb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["task1_classification_report.md"],"metadata":{"id":"fMKTNCMEA7Ea"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import classification_report\n","\n","task1_classification_report = classification_report(y_true, y_pred)\n","print(task1_classification_report)\n"],"metadata":{"id":"PPoQHwrsBFkT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["task1_classification_report = classification_report(y_true, y_pred, output_dict=True)\n"],"metadata":{"id":"9plRurSMBPOL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","report_dict = classification_report(y_true, y_pred, output_dict=True)\n","df = pd.DataFrame(report_dict).transpose()\n","df\n"],"metadata":{"id":"Z39Ug47PBTIS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from sklearn.metrics import classification_report\n","\n","model.eval()\n","\n","y_true = []\n","y_pred = []\n","\n","with torch.no_grad():\n","    for images, labels in test_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        outputs = model(images)\n","        preds = torch.argmax(outputs, dim=1)\n","\n","        y_true.extend(labels.cpu().numpy())\n","        y_pred.extend(preds.cpu().numpy())\n"],"metadata":{"id":"pOfEASfIBeFb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)\n"],"metadata":{"id":"eCS9UCs_BoDr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from sklearn.metrics import classification_report\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)\n","model.eval()\n","\n","y_true = []\n","y_pred = []\n","\n","with torch.no_grad():\n","    for images, labels in test_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        outputs = model(images)\n","        preds = torch.argmax(outputs, dim=1)\n","\n","        y_true.extend(labels.cpu().numpy())\n","        y_pred.extend(preds.cpu().numpy())\n"],"metadata":{"id":"LGWvXjyJBsMq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import classification_report\n","import pandas as pd\n","\n","report_dict = classification_report(y_true, y_pred, output_dict=True)\n","df = pd.DataFrame(report_dict).transpose()\n","df\n"],"metadata":{"id":"UAezpyUEButU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import classification_report\n","\n","task1_classification_report = classification_report(y_true, y_pred)\n","print(task1_classification_report)\n"],"metadata":{"id":"6mIkjIdaB14z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["task1_classification_report.md"],"metadata":{"id":"3aOW_DEPDQLj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import classification_report\n","\n","task1_classification_report = classification_report(y_true, y_pred)\n","print(task1_classification_report)\n"],"metadata":{"id":"X0s42Mh9DZVs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.metrics import classification_report\n","\n","# Get report as dict\n","report_dict = classification_report(y_true, y_pred, output_dict=True)\n","\n","# Convert to DataFrame\n","df = pd.DataFrame(report_dict).transpose()\n","\n","# Display as markdown\n","print(df.to_markdown())\n"],"metadata":{"id":"zRR7fM7_DeQS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","from medmnist import PneumoniaMNIST\n","import pandas as pd\n","from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# -------------------------------\n","# 1Ô∏è‚É£ Setup device\n","# -------------------------------\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)\n","\n","# -------------------------------\n","# 2Ô∏è‚É£ Transforms & Dataset\n","# -------------------------------\n","train_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[.5], std=[.5])\n","])\n","test_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[.5], std=[.5])\n","])\n","\n","train_dataset = PneumoniaMNIST(split='train', transform=train_transform, download=True)\n","val_dataset   = PneumoniaMNIST(split='val', transform=test_transform, download=True)\n","test_dataset  = PneumoniaMNIST(split='test', transform=test_transform, download=True)\n","\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","val_loader   = DataLoader(val_dataset, batch_size=64, shuffle=False)\n","test_loader  = DataLoader(test_dataset, batch_size=64, shuffle=False)\n","\n","# -------------------------------\n","# 3Ô∏è‚É£ Load your trained model\n","# -------------------------------\n","# Example: a pretrained model placeholder\n","# Replace this with your actual model\n","import torch.nn as nn\n","class SimpleCNN(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv = nn.Sequential(\n","            nn.Conv2d(1, 16, 3, 1, 1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2)\n","        )\n","        self.fc = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Linear(16*14*14, 2)  # PneumoniaMNIST images are 28x28 grayscale\n","        )\n","    def forward(self, x):\n","        x = self.conv(x)\n","        x = self.fc(x)\n","        return x\n","\n","model = SimpleCNN().to(device)\n","# model.load_state_dict(torch.load('your_model.pth'))  # Load trained weights if available\n","model.eval()\n","\n","# -------------------------------\n","# 4Ô∏è‚É£ Evaluation: y_true, y_pred\n","# -------------------------------\n","y_true = []\n","y_pred = []\n","y_scores = []  # for ROC-AUC\n","\n","with torch.no_grad():\n","    for images, labels in test_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        outputs = model(images)\n","        probs = torch.softmax(outputs, dim=1)\n","        preds = torch.argmax(outputs, dim=1)\n","\n","        y_true.extend(labels.cpu().numpy())\n","        y_pred.extend(preds.cpu().numpy())\n","        y_scores.extend(probs[:,1].cpu().numpy())  # probability for class 1\n","\n","# -------------------------------\n","# 5Ô∏è‚É£ Classification Report\n","# -------------------------------\n","report_dict = classification_report(y_true, y_pred, output_dict=True)\n","df_report = pd.DataFrame(report_dict).transpose()\n","print(\"‚úÖ Classification Report:\\n\")\n","print(df_report.to_markdown())\n","\n","# -------------------------------\n","# 6Ô∏è‚É£ Confusion Matrix\n","# -------------------------------\n","cm = confusion_matrix(y_true, y_pred)\n","plt.figure(figsize=(5,5))\n","sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Normal','Pneumonia'], yticklabels=['Normal','Pneumonia'])\n","plt.xlabel(\"Predicted\")\n","plt.ylabel(\"True\")\n","plt.title(\"Confusion Matrix\")\n","plt.show()\n","\n","# -------------------------------\n","# 7Ô∏è‚É£ ROC Curve & AUC\n","# -------------------------------\n","roc_auc = roc_auc_score(y_true, y_scores)\n","fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n","\n","plt.figure()\n","plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.3f}\")\n","plt.plot([0,1], [0,1], linestyle='--')\n","plt.xlabel(\"False Positive Rate\")\n","plt.ylabel(\"True Positive Rate\")\n","plt.title(\"ROC Curve\")\n","plt.legend()\n","plt.show()\n"],"metadata":{"id":"l1hvUliTDvXy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","from medmnist import PneumoniaMNIST\n","import pandas as pd\n","from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# -------------------------------\n","# 1Ô∏è‚É£ Device\n","# -------------------------------\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)\n","\n","# -------------------------------\n","# 2Ô∏è‚É£ Transforms & Dataset\n","# -------------------------------\n","train_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[.5], std=[.5])\n","])\n","test_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[.5], std=[.5])\n","])\n","\n","train_dataset = PneumoniaMNIST(split='train', transform=train_transform, download=True)\n","val_dataset   = PneumoniaMNIST(split='val', transform=test_transform, download=True)\n","test_dataset  = PneumoniaMNIST(split='test', transform=test_transform, download=True)\n","\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","val_loader   = DataLoader(val_dataset, batch_size=64, shuffle=False)\n","test_loader  = DataLoader(test_dataset, batch_size=64, shuffle=False)\n","\n","# -------------------------------\n","# 3Ô∏è‚É£ Simple CNN\n","# -------------------------------\n","class SimpleCNN(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv = nn.Sequential(\n","            nn.Conv2d(1, 16, 3, 1, 1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),\n","            nn.Conv2d(16, 32, 3, 1, 1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2)\n","        )\n","        self.fc = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Linear(32*7*7, 64),\n","            nn.ReLU(),\n","            nn.Linear(64, 2)\n","        )\n","    def forward(self, x):\n","        x = self.conv(x)\n","        x = self.fc(x)\n","        return x\n","\n","model = SimpleCNN().to(device)\n","\n","# -------------------------------\n","# 4Ô∏è‚É£ Loss & Optimizer\n","# -------------------------------\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# -------------------------------\n","# 5Ô∏è‚É£ Training Loop\n","# -------------------------------\n","epochs = 5  # adjust as needed\n","for epoch in range(epochs):\n","    model.train()\n","    running_loss = 0\n","    for images, labels in train_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","\n","    print(f\"Epoch {epoch+1}/{epochs} - Loss: {running_loss/len(train_loader):.4f}\")\n","\n","# -------------------------------\n","# 6Ô∏è‚É£ Evaluation\n","# -------------------------------\n","model.eval()\n","y_true = []\n","y_pred = []\n","y_scores = []\n","\n","with torch.no_grad():\n","    for images, labels in test_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        outputs = model(images)\n","        probs = torch.softmax(outputs, dim=1)\n","        preds = torch.argmax(outputs, dim=1)\n","\n","        y_true.extend(labels.cpu().numpy())\n","        y_pred.extend(preds.cpu().numpy())\n","        y_scores.extend(probs[:,1].cpu().numpy())  # probability for class 1\n","\n","# -------------------------------\n","# 7Ô∏è‚É£ Classification Report\n","# -------------------------------\n","report_dict = classification_report(y_true, y_pred, output_dict=True)\n","df_report = pd.DataFrame(report_dict).transpose()\n","print(\"‚úÖ Classification Report:\\n\")\n","print(df_report.to_markdown())\n","\n","# -------------------------------\n","# 8Ô∏è‚É£ Confusion Matrix\n","# -------------------------------\n","cm = confusion_matrix(y_true, y_pred)\n","plt.figure(figsize=(5,5))\n","sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Normal','Pneumonia'], yticklabels=['Normal','Pneumonia'])\n","plt.xlabel(\"Predicted\")\n","plt.ylabel(\"True\")\n","plt.title(\"Confusion Matrix\")\n","plt.show()\n","\n","# -------------------------------\n","# 9Ô∏è‚É£ ROC Curve\n","# -------------------------------\n","roc_auc = roc_auc_score(y_true, y_scores)\n","fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n","\n","plt.figure()\n","plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.3f}\")\n","plt.plot([0,1], [0,1], linestyle='--')\n","plt.xlabel(\"False Positive Rate\")\n","plt.ylabel(\"True Positive Rate\")\n","plt.title(\"ROC Curve\")\n","plt.legend()\n","plt.show()\n"],"metadata":{"id":"rZbw-1R_EApz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["labels = labels.squeeze().long()\n"],"metadata":{"id":"TPpeoBTDEIrk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for images, labels in train_loader:\n","    images = images.to(device)\n","    labels = labels.to(device).squeeze().long()  # <--- fix here\n","\n","    optimizer.zero_grad()\n","    outputs = model(images)\n","    loss = criterion(outputs, labels)\n","    loss.backward()\n","    optimizer.step()\n"],"metadata":{"id":"FQJsRWfOEKKj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["labels = labels.to(device).squeeze().long()\n","for images, labels in train_loader:\n","    print(labels.shape)  # should be [batch_size, 1]\n","    print(labels.unique())  # should be [0,1]\n","    break\n","\n"],"metadata":{"id":"HV7egO8VEQCc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","from medmnist import PneumoniaMNIST\n","import pandas as pd\n","from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import copy\n","\n","# -------------------------------\n","# 1Ô∏è‚É£ Device\n","# -------------------------------\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)\n","\n","# -------------------------------\n","# 2Ô∏è‚É£ Transforms & Dataset\n","# -------------------------------\n","train_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[.5], std=[.5])\n","])\n","test_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[.5], std=[.5])\n","])\n","\n","train_dataset = PneumoniaMNIST(split='train', transform=train_transform, download=True)\n","val_dataset   = PneumoniaMNIST(split='val', transform=test_transform, download=True)\n","test_dataset  = PneumoniaMNIST(split='test', transform=test_transform, download=True)\n","\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","val_loader   = DataLoader(val_dataset, batch_size=64, shuffle=False)\n","test_loader  = DataLoader(test_dataset, batch_size=64, shuffle=False)\n","\n","# -------------------------------\n","# 3Ô∏è‚É£ Simple CNN\n","# -------------------------------\n","class SimpleCNN(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv = nn.Sequential(\n","            nn.Conv2d(1, 16, 3, 1, 1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),\n","            nn.Conv2d(16, 32, 3, 1, 1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2)\n","        )\n","        self.fc = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Linear(32*7*7, 64),\n","            nn.ReLU(),\n","            nn.Linear(64, 2)\n","        )\n","    def forward(self, x):\n","        x = self.conv(x)\n","        x = self.fc(x)\n","        return x\n","\n","model = SimpleCNN().to(device)\n","\n","# -------------------------------\n","# 4Ô∏è‚É£ Loss & Optimizer\n","# -------------------------------\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# -------------------------------\n","# 5Ô∏è‚É£ Early Stopping Parameters\n","# -------------------------------\n","patience = 3\n","best_val_loss = float('inf')\n","epochs_no_improve = 0\n","best_model_wts = copy.deepcopy(model.state_dict())\n","num_epochs = 20\n","\n","# -------------------------------\n","# 6Ô∏è‚É£ Training Loop with Early Stopping\n","# -------------------------------\n","for epoch in range(num_epochs):\n","    # --- Training ---\n","    model.train()\n","    running_loss = 0\n","    for images, labels in train_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item()\n","    train_loss = running_loss / len(train_loader)\n","\n","    # --- Validation ---\n","    model.eval()\n","    val_loss = 0\n","    with torch.no_grad():\n","        for images, labels in val_loader:\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            val_loss += loss.item()\n","    val_loss /= len(val_loader)\n","\n","    print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f} - Val Loss: {val_loss:.4f}\")\n","\n","    # --- Check for early stopping ---\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        epochs_no_improve = 0\n","        best_model_wts = copy.deepcopy(model.state_dict())\n","    else:\n","        epochs_no_improve += 1\n","        if epochs_no_improve >= patience:\n","            print(f\"Early stopping triggered after {epoch+1} epochs.\")\n","            break\n","\n","# Load best model weights\n","model.load_state_dict(best_model_wts)\n","\n","# -------------------------------\n","# 7Ô∏è‚É£ Evaluation\n","# -------------------------------\n","model.eval()\n","y_true = []\n","y_pred = []\n","y_scores = []\n","\n","with torch.no_grad():\n","    for images, labels in test_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        outputs = model(images)\n","        probs = torch.softmax(outputs, dim=1)\n","        preds = torch.argmax(outputs, dim=1)\n","\n","        y_true.extend(labels.cpu().numpy())\n","        y_pred.extend(preds.cpu().numpy())\n","        y_scores.extend(probs[:,1].cpu().numpy())\n","\n","# -------------------------------\n","# 8Ô∏è‚É£ Classification Report\n","# -------------------------------\n","report_dict = classification_report(y_true, y_pred, output_dict=True)\n","df_report = pd.DataFrame(report_dict).transpose()\n","print(\"‚úÖ Classification Report:\\n\")\n","print(df_report.to_markdown())\n","\n","# -------------------------------\n","# 9Ô∏è‚É£ Confusion Matrix\n","# -------------------------------\n","cm = confusion_matrix(y_true, y_pred)\n","plt.figure(figsize=(5,5))\n","sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Normal','Pneumonia'], yticklabels=['Normal','Pneumonia'])\n","plt.xlabel(\"Predicted\")\n","plt.ylabel(\"True\")\n","plt.title(\"Confusion Matrix\")\n","plt.show()\n","\n","# -------------------------------\n","# üîü ROC Curve\n","# -------------------------------\n","roc_auc = roc_auc_score(y_true, y_scores)\n","fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n","\n","plt.figure()\n","plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.3f}\")\n","plt.plot([0,1], [0,1], linestyle='--')\n","plt.xlabel(\"False Positive Rate\")\n","plt.ylabel(\"True Positive Rate\")\n","plt.title(\"ROC Curve\")\n","plt.legend()\n","plt.show()\n"],"metadata":{"id":"iJ3pzGyHEWrT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["labels = labels.squeeze().long()\n","for images, labels in train_loader:\n","    images = images.to(device)\n","    labels = labels.to(device).squeeze().long()  # ‚úÖ fix here\n","\n","    optimizer.zero_grad()\n","    outputs = model(images)\n","    loss = criterion(outputs, labels)\n","    loss.backward()\n","    optimizer.step()\n","with torch.no_grad():\n","    for images, labels in val_loader:\n","        images = images.to(device)\n","        labels = labels.to(device).squeeze().long()  # ‚úÖ same fix\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        with torch.no_grad():\n","\n","\n","\n"],"metadata":{"id":"vPti6M1EEew0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for images, labels in val_loader:\n","        images = images.to(device)\n","        labels = labels.to(device).squeeze().long()  # ‚úÖ same fix\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)"],"metadata":{"id":"DXUKdqpMEsZl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for images, labels in train_loader:\n","    print(\"Shape:\", labels.shape)  # should now be [batch_size]\n","    print(\"Unique labels:\", labels.unique())  # should be [0,1]\n","    break\n"],"metadata":{"id":"85eMr6uuEwVN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","from medmnist import PneumoniaMNIST\n","import pandas as pd\n","from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import copy\n","\n","# -------------------------------\n","# 1Ô∏è‚É£ Device\n","# -------------------------------\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)\n","\n","# -------------------------------\n","# 2Ô∏è‚É£ Transforms & Dataset\n","# -------------------------------\n","train_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[.5], std=[.5])\n","])\n","test_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[.5], std=[.5])\n","])\n","\n","train_dataset = PneumoniaMNIST(split='train', transform=train_transform, download=True)\n","val_dataset   = PneumoniaMNIST(split='val', transform=test_transform, download=True)\n","test_dataset  = PneumoniaMNIST(split='test', transform=test_transform, download=True)\n","\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","val_loader   = DataLoader(val_dataset, batch_size=64, shuffle=False)\n","test_loader  = DataLoader(test_dataset, batch_size=64, shuffle=False)\n","\n","# -------------------------------\n","# 3Ô∏è‚É£ Simple CNN\n","# -------------------------------\n","class SimpleCNN(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv = nn.Sequential(\n","            nn.Conv2d(1, 16, 3, 1, 1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),\n","            nn.Conv2d(16, 32, 3, 1, 1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2)\n","        )\n","        self.fc = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Linear(32*7*7, 64),\n","            nn.ReLU(),\n","            nn.Linear(64, 2)\n","        )\n","    def forward(self, x):\n","        x = self.conv(x)\n","        x = self.fc(x)\n","        return x\n","\n","model = SimpleCNN().to(device)\n","\n","# -------------------------------\n","# 4Ô∏è‚É£ Loss & Optimizer\n","# -------------------------------\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# -------------------------------\n","# 5Ô∏è‚É£ Early Stopping Parameters\n","# -------------------------------\n","patience = 3\n","best_val_loss = float('inf')\n","epochs_no_improve = 0\n","best_model_wts = copy.deepcopy(model.state_dict())\n","num_epochs = 20\n","\n","# -------------------------------\n","# 6Ô∏è‚É£ Training Loop with Early Stopping\n","# -------------------------------\n","for epoch in range(num_epochs):\n","    # --- Training ---\n","    model.train()\n","    running_loss = 0\n","    for images, labels in train_loader:\n","        images = images.to(device)\n","        labels = labels.to(device).squeeze().long()  # ‚úÖ fix for PneumoniaMNIST\n","\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item()\n","    train_loss = running_loss / len(train_loader)\n","\n","    # --- Validation ---\n","    model.eval()\n","    val_loss = 0\n","    with torch.no_grad():\n","        for images, labels in val_loader:\n","            images = images.to(device)\n","            labels = labels.to(device).squeeze().long()  # ‚úÖ fix\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            val_loss += loss.item()\n","    val_loss /= len(val_loader)\n","\n","    print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f} - Val Loss: {val_loss:.4f}\")\n","\n","    # --- Early Stopping Check ---\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        epochs_no_improve = 0\n","        best_model_wts = copy.deepcopy(model.state_dict())\n","    else:\n","        epochs_no_improve += 1\n","        if epochs_no_improve >= patience:\n","            print(f\"Early stopping triggered after {epoch+1} epochs.\")\n","            break\n","\n","# Load best model weights\n","model.load_state_dict(best_model_wts)\n","\n","# -------------------------------\n","# 7Ô∏è‚É£ Evaluation\n","# -------------------------------\n","model.eval()\n","y_true = []\n","y_pred = []\n","y_scores = []\n","\n","with torch.no_grad():\n","    for images, labels in test_loader:\n","        images = images.to(device)\n","        labels = labels.to(device).squeeze().long()  # ‚úÖ fix\n","        outputs = model(images)\n","        probs = torch.softmax(outputs, dim=1)\n","        preds = torch.argmax(outputs, dim=1)\n","\n","        y_true.extend(labels.cpu().numpy())\n","        y_pred.extend(preds.cpu().numpy())\n","        y_scores.extend(probs[:,1].cpu().numpy())\n","\n","# -------------------------------\n","# 8Ô∏è‚É£ Classification Report\n","# -------------------------------\n","report_dict = classification_report(y_true, y_pred, output_dict=True)\n","df_report = pd.DataFrame(report_dict).transpose()\n","print(\"‚úÖ Classification Report:\\n\")\n","print(df_report.to_markdown())\n","\n","# -------------------------------\n","# 9Ô∏è‚É£ Confusion Matrix\n","# -------------------------------\n","cm = confusion_matrix(y_true, y_pred)\n","plt.figure(figsize=(5,5))\n","sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Normal','Pneumonia'], yticklabels=['Normal','Pneumonia'])\n","plt.xlabel(\"Predicted\")\n","plt.ylabel(\"True\")\n","plt.title(\"Confusion Matrix\")\n","plt.show()\n","\n","# -------------------------------\n","# üîü ROC Curve\n","# -------------------------------\n","roc_auc = roc_auc_score(y_true, y_scores)\n","fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n","\n","plt.figure()\n","plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.3f}\")\n","plt.plot([0,1], [0,1], linestyle='--')\n","plt.xlabel(\"False Positive Rate\")\n","plt.ylabel(\"True Positive Rate\")\n","plt.title(\"ROC Curve\")\n","plt.legend()\n","plt.show()\n"],"metadata":{"id":"dWGvKttEE6O1"},"execution_count":null,"outputs":[]}]}