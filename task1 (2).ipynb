{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"u2MSWfXn9gAU"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","!pip install medmnist\n","from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import numpy as np"]},{"cell_type":"code","source":["!pip install nbformat"],"metadata":{"id":"9J_YoPIriDAR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","print(os.getcwd())\n","print(os.listdir())\n"],"metadata":{"id":"R0dQe65TjEyn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"id":"09wOVs3gjJAd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import files\n","uploaded = files.upload()\n"],"metadata":{"id":"xlVgCsDSjVbW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls\n"],"metadata":{"id":"wy9yy1GYjlP-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.RandomRotation(10),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.Normalize(mean=[0.5], std=[0.5])\n","])\n","\n","test_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.5], std=[0.5])\n","])\n"],"metadata":{"id":"2ItnqILu-cCz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from medmnist import PneumoniaMNIST\n","!pip install medmnist\n","\n","train_dataset = PneumoniaMNIST(split='train', transform=train_transform, download=True)\n","val_dataset = PneumoniaMNIST(split='val', transform=test_transform, download=True)\n","test_dataset = PneumoniaMNIST(split='test', transform=test_transform, download=True)\n","\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"],"metadata":{"id":"M1C8rvz8-lSL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from medmnist import PneumoniaMNIST"],"metadata":{"id":"uWoCG5u1-4LT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","from medmnist import PneumoniaMNIST\n"],"metadata":{"id":"n5HfNex4-7nz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset = PneumoniaMNIST(split='train', transform=train_transform, download=True)\n","val_dataset = PneumoniaMNIST(split='val', transform=test_transform, download=True)\n","test_dataset = PneumoniaMNIST(split='test', transform=test_transform, download=True)\n","\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"],"metadata":{"id":"IiSf4O7Y---D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class SimpleCNN(nn.Module):\n","    def __init__(self):\n","        super(SimpleCNN, self).__init__()\n","        self.features = nn.Sequential(\n","            nn.Conv2d(1, 32, 3, padding=1),\n","            nn.BatchNorm2d(32),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),\n","\n","            nn.Conv2d(32, 64, 3, padding=1),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),\n","\n","            nn.Conv2d(64, 128, 3, padding=1),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(),\n","            nn.AdaptiveAvgPool2d(1)\n","        )\n","\n","        self.classifier = nn.Linear(128, 1)\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = torch.flatten(x, 1)\n","        x = self.classifier(x)\n","        return x\n"],"metadata":{"id":"M5v79L1c_Cf7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = SimpleCNN()\n","criterion = nn.BCEWithLogitsLoss()\n","optimizer = optim.Adam(model.parameters(), lr=1e-3)\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n"],"metadata":{"id":"XpB5_f2z_HVb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def evaluate(model, loader):\n","    model.eval()\n","    preds, probs, labels_list = [], [], []\n","\n","    with torch.no_grad():\n","        for images, labels in loader:\n","            outputs = model(images).squeeze()\n","            probability = torch.sigmoid(outputs)\n","\n","            preds.extend((probability > 0.5).int().numpy())\n","            probs.extend(probability.numpy())\n","            labels_list.extend(labels.numpy())\n","\n","    return np.array(preds), np.array(probs), np.array(labels_list)\n"],"metadata":{"id":"YLa0jrQ-_KlS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["preds, probs, labels = evaluate(model, test_loader)\n","\n","print(classification_report(labels, preds))\n"],"metadata":{"id":"fp-eQzkh_PLT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cm = confusion_matrix(labels, preds)\n","\n","sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n","plt.xlabel(\"Predicted\")\n","plt.ylabel(\"Actual\")\n","plt.title(\"Confusion Matrix\")\n","plt.show()\n"],"metadata":{"id":"0gLqFA7w_SNj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["auc = roc_auc_score(labels, probs)\n","fpr, tpr, _ = roc_curve(labels, probs)\n","\n","plt.plot(fpr, tpr, label=f\"AUC = {auc:.3f}\")\n","plt.plot([0,1],[0,1],'--')\n","plt.xlabel(\"False Positive Rate\")\n","plt.ylabel(\"True Positive Rate\")\n","plt.title(\"ROC Curve\")\n","plt.legend()\n","plt.show()\n"],"metadata":{"id":"MqwCOT8g_YIr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["misclassified_indices = np.where(preds != labels)[0]\n"],"metadata":{"id":"241V6M6O_bWC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for idx in misclassified_indices[:5]:\n","    image, label = test_dataset[idx]\n","    plt.imshow(image.squeeze(), cmap='gray')\n","    plt.title(f\"True: {label}, Predicted: {preds[idx]}\")\n","    plt.show()\n"],"metadata":{"id":"a81TSOyp_eeb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["task1_classification_report.md"],"metadata":{"id":"fMKTNCMEA7Ea"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import classification_report\n","\n","task1_classification_report = classification_report(y_true, y_pred)\n","print(task1_classification_report)\n"],"metadata":{"id":"PPoQHwrsBFkT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["task1_classification_report = classification_report(y_true, y_pred, output_dict=True)\n"],"metadata":{"id":"9plRurSMBPOL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","report_dict = classification_report(y_true, y_pred, output_dict=True)\n","df = pd.DataFrame(report_dict).transpose()\n","df\n"],"metadata":{"id":"Z39Ug47PBTIS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from sklearn.metrics import classification_report\n","\n","model.eval()\n","\n","y_true = []\n","y_pred = []\n","\n","with torch.no_grad():\n","    for images, labels in test_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        outputs = model(images)\n","        preds = torch.argmax(outputs, dim=1)\n","\n","        y_true.extend(labels.cpu().numpy())\n","        y_pred.extend(preds.cpu().numpy())\n"],"metadata":{"id":"pOfEASfIBeFb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)\n"],"metadata":{"id":"eCS9UCs_BoDr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from sklearn.metrics import classification_report\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)\n","model.eval()\n","\n","y_true = []\n","y_pred = []\n","\n","with torch.no_grad():\n","    for images, labels in test_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        outputs = model(images)\n","        preds = torch.argmax(outputs, dim=1)\n","\n","        y_true.extend(labels.cpu().numpy())\n","        y_pred.extend(preds.cpu().numpy())\n"],"metadata":{"id":"LGWvXjyJBsMq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import classification_report\n","import pandas as pd\n","\n","report_dict = classification_report(y_true, y_pred, output_dict=True)\n","df = pd.DataFrame(report_dict).transpose()\n","df\n"],"metadata":{"id":"UAezpyUEButU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import classification_report\n","\n","task1_classification_report = classification_report(y_true, y_pred)\n","print(task1_classification_report)\n"],"metadata":{"id":"6mIkjIdaB14z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["task1_classification_report.md"],"metadata":{"id":"3aOW_DEPDQLj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import classification_report\n","\n","task1_classification_report = classification_report(y_true, y_pred)\n","print(task1_classification_report)\n"],"metadata":{"id":"X0s42Mh9DZVs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.metrics import classification_report\n","\n","# Get report as dict\n","report_dict = classification_report(y_true, y_pred, output_dict=True)\n","\n","# Convert to DataFrame\n","df = pd.DataFrame(report_dict).transpose()\n","\n","# Display as markdown\n","print(df.to_markdown())\n"],"metadata":{"id":"zRR7fM7_DeQS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","from medmnist import PneumoniaMNIST\n","import pandas as pd\n","from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# -------------------------------\n","# 1Ô∏è‚É£ Setup device\n","# -------------------------------\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)\n","\n","# -------------------------------\n","# 2Ô∏è‚É£ Transforms & Dataset\n","# -------------------------------\n","train_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[.5], std=[.5])\n","])\n","test_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[.5], std=[.5])\n","])\n","\n","train_dataset = PneumoniaMNIST(split='train', transform=train_transform, download=True)\n","val_dataset   = PneumoniaMNIST(split='val', transform=test_transform, download=True)\n","test_dataset  = PneumoniaMNIST(split='test', transform=test_transform, download=True)\n","\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","val_loader   = DataLoader(val_dataset, batch_size=64, shuffle=False)\n","test_loader  = DataLoader(test_dataset, batch_size=64, shuffle=False)\n","\n","# -------------------------------\n","# 3Ô∏è‚É£ Load your trained model\n","# -------------------------------\n","# Example: a pretrained model placeholder\n","# Replace this with your actual model\n","import torch.nn as nn\n","class SimpleCNN(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv = nn.Sequential(\n","            nn.Conv2d(1, 16, 3, 1, 1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2)\n","        )\n","        self.fc = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Linear(16*14*14, 2)  # PneumoniaMNIST images are 28x28 grayscale\n","        )\n","    def forward(self, x):\n","        x = self.conv(x)\n","        x = self.fc(x)\n","        return x\n","\n","model = SimpleCNN().to(device)\n","# model.load_state_dict(torch.load('your_model.pth'))  # Load trained weights if available\n","model.eval()\n","\n","# -------------------------------\n","# 4Ô∏è‚É£ Evaluation: y_true, y_pred\n","# -------------------------------\n","y_true = []\n","y_pred = []\n","y_scores = []  # for ROC-AUC\n","\n","with torch.no_grad():\n","    for images, labels in test_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        outputs = model(images)\n","        probs = torch.softmax(outputs, dim=1)\n","        preds = torch.argmax(outputs, dim=1)\n","\n","        y_true.extend(labels.cpu().numpy())\n","        y_pred.extend(preds.cpu().numpy())\n","        y_scores.extend(probs[:,1].cpu().numpy())  # probability for class 1\n","\n","# -------------------------------\n","# 5Ô∏è‚É£ Classification Report\n","# -------------------------------\n","report_dict = classification_report(y_true, y_pred, output_dict=True)\n","df_report = pd.DataFrame(report_dict).transpose()\n","print(\"‚úÖ Classification Report:\\n\")\n","print(df_report.to_markdown())\n","\n","# -------------------------------\n","# 6Ô∏è‚É£ Confusion Matrix\n","# -------------------------------\n","cm = confusion_matrix(y_true, y_pred)\n","plt.figure(figsize=(5,5))\n","sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Normal','Pneumonia'], yticklabels=['Normal','Pneumonia'])\n","plt.xlabel(\"Predicted\")\n","plt.ylabel(\"True\")\n","plt.title(\"Confusion Matrix\")\n","plt.show()\n","\n","# -------------------------------\n","# 7Ô∏è‚É£ ROC Curve & AUC\n","# -------------------------------\n","roc_auc = roc_auc_score(y_true, y_scores)\n","fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n","\n","plt.figure()\n","plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.3f}\")\n","plt.plot([0,1], [0,1], linestyle='--')\n","plt.xlabel(\"False Positive Rate\")\n","plt.ylabel(\"True Positive Rate\")\n","plt.title(\"ROC Curve\")\n","plt.legend()\n","plt.show()\n"],"metadata":{"id":"l1hvUliTDvXy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","from medmnist import PneumoniaMNIST\n","import pandas as pd\n","from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# -------------------------------\n","# 1Ô∏è‚É£ Device\n","# -------------------------------\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)\n","\n","# -------------------------------\n","# 2Ô∏è‚É£ Transforms & Dataset\n","# -------------------------------\n","train_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[.5], std=[.5])\n","])\n","test_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[.5], std=[.5])\n","])\n","\n","train_dataset = PneumoniaMNIST(split='train', transform=train_transform, download=True)\n","val_dataset   = PneumoniaMNIST(split='val', transform=test_transform, download=True)\n","test_dataset  = PneumoniaMNIST(split='test', transform=test_transform, download=True)\n","\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","val_loader   = DataLoader(val_dataset, batch_size=64, shuffle=False)\n","test_loader  = DataLoader(test_dataset, batch_size=64, shuffle=False)\n","\n","# -------------------------------\n","# 3Ô∏è‚É£ Simple CNN\n","# -------------------------------\n","class SimpleCNN(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv = nn.Sequential(\n","            nn.Conv2d(1, 16, 3, 1, 1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),\n","            nn.Conv2d(16, 32, 3, 1, 1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2)\n","        )\n","        self.fc = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Linear(32*7*7, 64),\n","            nn.ReLU(),\n","            nn.Linear(64, 2)\n","        )\n","    def forward(self, x):\n","        x = self.conv(x)\n","        x = self.fc(x)\n","        return x\n","\n","model = SimpleCNN().to(device)\n","\n","# -------------------------------\n","# 4Ô∏è‚É£ Loss & Optimizer\n","# -------------------------------\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# -------------------------------\n","# 5Ô∏è‚É£ Training Loop\n","# -------------------------------\n","epochs = 5  # adjust as needed\n","for epoch in range(epochs):\n","    model.train()\n","    running_loss = 0\n","    for images, labels in train_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","\n","    print(f\"Epoch {epoch+1}/{epochs} - Loss: {running_loss/len(train_loader):.4f}\")\n","\n","# -------------------------------\n","# 6Ô∏è‚É£ Evaluation\n","# -------------------------------\n","model.eval()\n","y_true = []\n","y_pred = []\n","y_scores = []\n","\n","with torch.no_grad():\n","    for images, labels in test_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        outputs = model(images)\n","        probs = torch.softmax(outputs, dim=1)\n","        preds = torch.argmax(outputs, dim=1)\n","\n","        y_true.extend(labels.cpu().numpy())\n","        y_pred.extend(preds.cpu().numpy())\n","        y_scores.extend(probs[:,1].cpu().numpy())  # probability for class 1\n","\n","# -------------------------------\n","# 7Ô∏è‚É£ Classification Report\n","# -------------------------------\n","report_dict = classification_report(y_true, y_pred, output_dict=True)\n","df_report = pd.DataFrame(report_dict).transpose()\n","print(\"‚úÖ Classification Report:\\n\")\n","print(df_report.to_markdown())\n","\n","# -------------------------------\n","# 8Ô∏è‚É£ Confusion Matrix\n","# -------------------------------\n","cm = confusion_matrix(y_true, y_pred)\n","plt.figure(figsize=(5,5))\n","sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Normal','Pneumonia'], yticklabels=['Normal','Pneumonia'])\n","plt.xlabel(\"Predicted\")\n","plt.ylabel(\"True\")\n","plt.title(\"Confusion Matrix\")\n","plt.show()\n","\n","# -------------------------------\n","# 9Ô∏è‚É£ ROC Curve\n","# -------------------------------\n","roc_auc = roc_auc_score(y_true, y_scores)\n","fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n","\n","plt.figure()\n","plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.3f}\")\n","plt.plot([0,1], [0,1], linestyle='--')\n","plt.xlabel(\"False Positive Rate\")\n","plt.ylabel(\"True Positive Rate\")\n","plt.title(\"ROC Curve\")\n","plt.legend()\n","plt.show()\n"],"metadata":{"id":"rZbw-1R_EApz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["labels = labels.squeeze().long()\n"],"metadata":{"id":"TPpeoBTDEIrk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for images, labels in train_loader:\n","    images = images.to(device)\n","    labels = labels.to(device).squeeze().long()  # <--- fix here\n","\n","    optimizer.zero_grad()\n","    outputs = model(images)\n","    loss = criterion(outputs, labels)\n","    loss.backward()\n","    optimizer.step()\n"],"metadata":{"id":"FQJsRWfOEKKj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["labels = labels.to(device).squeeze().long()\n","for images, labels in train_loader:\n","    print(labels.shape)  # should be [batch_size, 1]\n","    print(labels.unique())  # should be [0,1]\n","    break\n","\n"],"metadata":{"id":"HV7egO8VEQCc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","from medmnist import PneumoniaMNIST\n","import pandas as pd\n","from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import copy\n","\n","# -------------------------------\n","# 1Ô∏è‚É£ Device\n","# -------------------------------\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)\n","\n","# -------------------------------\n","# 2Ô∏è‚É£ Transforms & Dataset\n","# -------------------------------\n","train_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[.5], std=[.5])\n","])\n","test_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[.5], std=[.5])\n","])\n","\n","train_dataset = PneumoniaMNIST(split='train', transform=train_transform, download=True)\n","val_dataset   = PneumoniaMNIST(split='val', transform=test_transform, download=True)\n","test_dataset  = PneumoniaMNIST(split='test', transform=test_transform, download=True)\n","\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","val_loader   = DataLoader(val_dataset, batch_size=64, shuffle=False)\n","test_loader  = DataLoader(test_dataset, batch_size=64, shuffle=False)\n","\n","# -------------------------------\n","# 3Ô∏è‚É£ Simple CNN\n","# -------------------------------\n","class SimpleCNN(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv = nn.Sequential(\n","            nn.Conv2d(1, 16, 3, 1, 1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),\n","            nn.Conv2d(16, 32, 3, 1, 1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2)\n","        )\n","        self.fc = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Linear(32*7*7, 64),\n","            nn.ReLU(),\n","            nn.Linear(64, 2)\n","        )\n","    def forward(self, x):\n","        x = self.conv(x)\n","        x = self.fc(x)\n","        return x\n","\n","model = SimpleCNN().to(device)\n","\n","# -------------------------------\n","# 4Ô∏è‚É£ Loss & Optimizer\n","# -------------------------------\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# -------------------------------\n","# 5Ô∏è‚É£ Early Stopping Parameters\n","# -------------------------------\n","patience = 3\n","best_val_loss = float('inf')\n","epochs_no_improve = 0\n","best_model_wts = copy.deepcopy(model.state_dict())\n","num_epochs = 20\n","\n","# -------------------------------\n","# 6Ô∏è‚É£ Training Loop with Early Stopping\n","# -------------------------------\n","for epoch in range(num_epochs):\n","    # --- Training ---\n","    model.train()\n","    running_loss = 0\n","    for images, labels in train_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item()\n","    train_loss = running_loss / len(train_loader)\n","\n","    # --- Validation ---\n","    model.eval()\n","    val_loss = 0\n","    with torch.no_grad():\n","        for images, labels in val_loader:\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            val_loss += loss.item()\n","    val_loss /= len(val_loader)\n","\n","    print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f} - Val Loss: {val_loss:.4f}\")\n","\n","    # --- Check for early stopping ---\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        epochs_no_improve = 0\n","        best_model_wts = copy.deepcopy(model.state_dict())\n","    else:\n","        epochs_no_improve += 1\n","        if epochs_no_improve >= patience:\n","            print(f\"Early stopping triggered after {epoch+1} epochs.\")\n","            break\n","\n","# Load best model weights\n","model.load_state_dict(best_model_wts)\n","\n","# -------------------------------\n","# 7Ô∏è‚É£ Evaluation\n","# -------------------------------\n","model.eval()\n","y_true = []\n","y_pred = []\n","y_scores = []\n","\n","with torch.no_grad():\n","    for images, labels in test_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        outputs = model(images)\n","        probs = torch.softmax(outputs, dim=1)\n","        preds = torch.argmax(outputs, dim=1)\n","\n","        y_true.extend(labels.cpu().numpy())\n","        y_pred.extend(preds.cpu().numpy())\n","        y_scores.extend(probs[:,1].cpu().numpy())\n","\n","# -------------------------------\n","# 8Ô∏è‚É£ Classification Report\n","# -------------------------------\n","report_dict = classification_report(y_true, y_pred, output_dict=True)\n","df_report = pd.DataFrame(report_dict).transpose()\n","print(\"‚úÖ Classification Report:\\n\")\n","print(df_report.to_markdown())\n","\n","# -------------------------------\n","# 9Ô∏è‚É£ Confusion Matrix\n","# -------------------------------\n","cm = confusion_matrix(y_true, y_pred)\n","plt.figure(figsize=(5,5))\n","sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Normal','Pneumonia'], yticklabels=['Normal','Pneumonia'])\n","plt.xlabel(\"Predicted\")\n","plt.ylabel(\"True\")\n","plt.title(\"Confusion Matrix\")\n","plt.show()\n","\n","# -------------------------------\n","# üîü ROC Curve\n","# -------------------------------\n","roc_auc = roc_auc_score(y_true, y_scores)\n","fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n","\n","plt.figure()\n","plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.3f}\")\n","plt.plot([0,1], [0,1], linestyle='--')\n","plt.xlabel(\"False Positive Rate\")\n","plt.ylabel(\"True Positive Rate\")\n","plt.title(\"ROC Curve\")\n","plt.legend()\n","plt.show()\n"],"metadata":{"id":"iJ3pzGyHEWrT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["labels = labels.squeeze().long()\n","for images, labels in train_loader:\n","    images = images.to(device)\n","    labels = labels.to(device).squeeze().long()  # ‚úÖ fix here\n","\n","    optimizer.zero_grad()\n","    outputs = model(images)\n","    loss = criterion(outputs, labels)\n","    loss.backward()\n","    optimizer.step()\n","with torch.no_grad():\n","    for images, labels in val_loader:\n","        images = images.to(device)\n","        labels = labels.to(device).squeeze().long()  # ‚úÖ same fix\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        with torch.no_grad():\n","\n","\n","\n"],"metadata":{"id":"vPti6M1EEew0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for images, labels in val_loader:\n","        images = images.to(device)\n","        labels = labels.to(device).squeeze().long()  # ‚úÖ same fix\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)"],"metadata":{"id":"DXUKdqpMEsZl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for images, labels in train_loader:\n","    print(\"Shape:\", labels.shape)  # should now be [batch_size]\n","    print(\"Unique labels:\", labels.unique())  # should be [0,1]\n","    break\n"],"metadata":{"id":"85eMr6uuEwVN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","from medmnist import PneumoniaMNIST\n","import pandas as pd\n","from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import copy\n","\n","# -------------------------------\n","# 1Ô∏è‚É£ Device\n","# -------------------------------\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)\n","\n","# -------------------------------\n","# 2Ô∏è‚É£ Transforms & Dataset\n","# -------------------------------\n","train_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[.5], std=[.5])\n","])\n","test_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[.5], std=[.5])\n","])\n","\n","train_dataset = PneumoniaMNIST(split='train', transform=train_transform, download=True)\n","val_dataset   = PneumoniaMNIST(split='val', transform=test_transform, download=True)\n","test_dataset  = PneumoniaMNIST(split='test', transform=test_transform, download=True)\n","\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","val_loader   = DataLoader(val_dataset, batch_size=64, shuffle=False)\n","test_loader  = DataLoader(test_dataset, batch_size=64, shuffle=False)\n","\n","# -------------------------------\n","# 3Ô∏è‚É£ Simple CNN\n","# -------------------------------\n","class SimpleCNN(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv = nn.Sequential(\n","            nn.Conv2d(1, 16, 3, 1, 1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),\n","            nn.Conv2d(16, 32, 3, 1, 1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2)\n","        )\n","        self.fc = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Linear(32*7*7, 64),\n","            nn.ReLU(),\n","            nn.Linear(64, 2)\n","        )\n","    def forward(self, x):\n","        x = self.conv(x)\n","        x = self.fc(x)\n","        return x\n","\n","model = SimpleCNN().to(device)\n","\n","# -------------------------------\n","# 4Ô∏è‚É£ Loss & Optimizer\n","# -------------------------------\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# -------------------------------\n","# 5Ô∏è‚É£ Early Stopping Parameters\n","# -------------------------------\n","patience = 3\n","best_val_loss = float('inf')\n","epochs_no_improve = 0\n","best_model_wts = copy.deepcopy(model.state_dict())\n","num_epochs = 20\n","\n","# -------------------------------\n","# 6Ô∏è‚É£ Training Loop with Early Stopping\n","# -------------------------------\n","for epoch in range(num_epochs):\n","    # --- Training ---\n","    model.train()\n","    running_loss = 0\n","    for images, labels in train_loader:\n","        images = images.to(device)\n","        labels = labels.to(device).squeeze().long()  # ‚úÖ fix for PneumoniaMNIST\n","\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item()\n","    train_loss = running_loss / len(train_loader)\n","\n","    # --- Validation ---\n","    model.eval()\n","    val_loss = 0\n","    with torch.no_grad():\n","        for images, labels in val_loader:\n","            images = images.to(device)\n","            labels = labels.to(device).squeeze().long()  # ‚úÖ fix\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            val_loss += loss.item()\n","    val_loss /= len(val_loader)\n","\n","    print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f} - Val Loss: {val_loss:.4f}\")\n","\n","    # --- Early Stopping Check ---\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        epochs_no_improve = 0\n","        best_model_wts = copy.deepcopy(model.state_dict())\n","    else:\n","        epochs_no_improve += 1\n","        if epochs_no_improve >= patience:\n","            print(f\"Early stopping triggered after {epoch+1} epochs.\")\n","            break\n","\n","# Load best model weights\n","model.load_state_dict(best_model_wts)\n","\n","# -------------------------------\n","# 7Ô∏è‚É£ Evaluation\n","# -------------------------------\n","model.eval()\n","y_true = []\n","y_pred = []\n","y_scores = []\n","\n","with torch.no_grad():\n","    for images, labels in test_loader:\n","        images = images.to(device)\n","        labels = labels.to(device).squeeze().long()  # ‚úÖ fix\n","        outputs = model(images)\n","        probs = torch.softmax(outputs, dim=1)\n","        preds = torch.argmax(outputs, dim=1)\n","\n","        y_true.extend(labels.cpu().numpy())\n","        y_pred.extend(preds.cpu().numpy())\n","        y_scores.extend(probs[:,1].cpu().numpy())\n","\n","# -------------------------------\n","# 8Ô∏è‚É£ Classification Report\n","# -------------------------------\n","report_dict = classification_report(y_true, y_pred, output_dict=True)\n","df_report = pd.DataFrame(report_dict).transpose()\n","print(\"‚úÖ Classification Report:\\n\")\n","print(df_report.to_markdown())\n","\n","# -------------------------------\n","# 9Ô∏è‚É£ Confusion Matrix\n","# -------------------------------\n","cm = confusion_matrix(y_true, y_pred)\n","plt.figure(figsize=(5,5))\n","sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Normal','Pneumonia'], yticklabels=['Normal','Pneumonia'])\n","plt.xlabel(\"Predicted\")\n","plt.ylabel(\"True\")\n","plt.title(\"Confusion Matrix\")\n","plt.show()\n","\n","# -------------------------------\n","# üîü ROC Curve\n","# -------------------------------\n","roc_auc = roc_auc_score(y_true, y_scores)\n","fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n","\n","plt.figure()\n","plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.3f}\")\n","plt.plot([0,1], [0,1], linestyle='--')\n","plt.xlabel(\"False Positive Rate\")\n","plt.ylabel(\"True Positive Rate\")\n","plt.title(\"ROC Curve\")\n","plt.legend()\n","plt.show()\n"],"metadata":{"id":"dWGvKttEE6O1"},"execution_count":null,"outputs":[]}]}